{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig. 2A & Fig. S5\n",
    "#Step 1: Open the total.net/maximum_spanning_tree file in 'D:Fig_2' with pajek \n",
    "#Step 2: using the Kamada Kawai layout algorithm to draw the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the common neighbors of components in the original network data\n",
    "file_path='D:Fig_2/original_data/'\n",
    "files=os.listdir(file_path)\n",
    "files.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "for file in files:\n",
    "    position=file_path+file\n",
    "    df=pd.read_csv(position,encoding='gbk')\n",
    "    df.set_index('herb1',inplace=True)\n",
    "    df.columns.name='herb2'\n",
    "    G=nx.Graph()\n",
    "    idx=list(df.columns)\n",
    "    G.add_nodes_from(idx)\n",
    "    for i in range(len(idx)):\n",
    "        for j in range(len(idx)):\n",
    "            if df.loc[idx[i],idx[j]] != 0:\n",
    "                G.add_edge(idx[i],idx[j])\n",
    "    new_df=df.copy()\n",
    "    new_df[new_df>0]=0\n",
    "    for i in range(len(idx)):\n",
    "        for j in range(len(idx)):\n",
    "            if idx[i]!=idx[j]:\n",
    "                new_df.loc[idx[i],idx[j]]=len(list(nx.common_neighbors(G,idx[i],idx[j])))\n",
    "    new_df.to_csv('D:Fig_2/original_common_neighbor/'+file,encoding='gbk')\n",
    "\n",
    "#calculate the NODF value of the original network\n",
    "file_path1='D:Fig_2/original_data/'\n",
    "file_path2='D:Fig_2/original_common_neighbor/'\n",
    "files1=os.listdir(file_path1)\n",
    "files1.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "times=[]\n",
    "NODF=[]\n",
    "for s in range(len(files1)):\n",
    "    print(files1[s])\n",
    "    time=files1[s].replace('.csv','')\n",
    "    position1=file_path1+files1[s]\n",
    "    position2=file_path2+files1[s]\n",
    "    df1=pd.read_csv(position1,encoding='gbk')\n",
    "    df1.set_index('herb1',inplace=True)\n",
    "    df1[df1>0]=1\n",
    "    degree=list(df1.apply(lambda x:x.sum(),axis=0))\n",
    "    df2=pd.read_csv(position2,encoding='gbk')\n",
    "    df2.set_index('herb1',inplace=True)\n",
    "\n",
    "    NR2=[]\n",
    "    for i in range(len(df2)):\n",
    "        NR1=[]\n",
    "        for j in range(len(df2)):\n",
    "            if j > i:\n",
    "                if degree[j] == 0:\n",
    "                    NR1.append(0)\n",
    "                else:\n",
    "                    NR1.append(df2.iloc[i,j]/degree[j])\n",
    "        sum_r=sum(NR1)\n",
    "        NR2.append(sum_r)\n",
    "    NODF.append((sum(NR2)*2)/(len(df2)*(len(df2)-1)))\n",
    "    times.append(time)\n",
    "new_df=pd.DataFrame()\n",
    "new_df['time']=times\n",
    "new_df['NODF']=NODF\n",
    "new_df.to_csv('D:Fig_2/original_nestedness.csv',index=False,encoding='gbk')\n",
    "\n",
    "#acquire the null model of the original network\n",
    "file_path='D:Fig_2/original_data/'\n",
    "files=os.listdir(file_path)\n",
    "files.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "file_path1='D:Fig_2/null_model_data/'\n",
    "for i in range(len(files)):\n",
    "    print(files[i].replace('.csv',''))\n",
    "    G=nx.Graph()\n",
    "    position=file_path+files[i]\n",
    "    df=pd.read_csv(position,encoding='gbk')\n",
    "    df.set_index('herb1',inplace=True)\n",
    "    \n",
    "    for s in range(len(df)):\n",
    "        for t in range(len(df)):\n",
    "            if s > t:\n",
    "                df.iloc[s,t]=0\n",
    "    herbs=list(df.index)\n",
    "    \n",
    "    G.add_nodes_from(herbs)\n",
    "    for s in range(len(df)):\n",
    "        for t in range(len(df)):\n",
    "            if df.iloc[s,t] != 0:\n",
    "                G.add_edge(herbs[s],herbs[t])\n",
    "    number_n=len(G.nodes())\n",
    "    number_e=len(G.edges())\n",
    "    total_n=number_n*(number_n-1)/2\n",
    "\n",
    "    #construct the random network\n",
    "    while True:\n",
    "        R_G=nx.erdos_renyi_graph(number_n,number_e/total_n)\n",
    "        if len(R_G.edges()) == number_e:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    new_df=pd.DataFrame(np.random.rand(number_n*number_n).reshape(number_n,number_n),index=herbs,columns=herbs)\n",
    "    new_df[new_df>0]=0\n",
    "    e=list(R_G.edges())\n",
    "    for item in e:\n",
    "        for m in range(len(herbs)):\n",
    "            if m == item[0]: \n",
    "                for n in range(len(herbs)):\n",
    "                    if n == item[1]:\n",
    "                        new_df.loc[herbs[m],herbs[n]] = 1\n",
    "    new_df.to_csv(file_path1+files[i],encoding='gbk')\n",
    "\n",
    "#find the common neighbors of components in the random network data\n",
    "file_path='D:Fig_2/null_model_data/'\n",
    "files=os.listdir(file_path)\n",
    "files.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "\n",
    "for file in files:\n",
    "    position=file_path+file\n",
    "    df=pd.read_csv(position,encoding='gbk')\n",
    "    df.set_index('herb1',inplace=True)\n",
    "    df.columns.name='herb2'\n",
    "    G=nx.Graph()\n",
    "    idx=list(df.columns)\n",
    "    G.add_nodes_from(idx)\n",
    "    for i in range(len(idx)):\n",
    "        for j in range(len(idx)):\n",
    "            if df.loc[idx[i],idx[j]] != 0:\n",
    "                G.add_edge(idx[i],idx[j])\n",
    "    new_df=df.copy()\n",
    "    new_df[new_df>0]=0\n",
    "    for i in range(len(idx)):\n",
    "        for j in range(len(idx)):\n",
    "            if idx[i]!=idx[j]:\n",
    "                new_df.loc[idx[i],idx[j]]=len(list(nx.common_neighbors(G,idx[i],idx[j])))\n",
    "    new_df.to_csv('D:Fig_2/null_model_common_neighbor/'+file,encoding='gbk')\n",
    "\n",
    "#sort the null model data and null model common neighbor data according to degrees of components\n",
    "#null model data\n",
    "file_path='D:Fig_2/null_model_data/'\n",
    "files=os.listdir(file_path)\n",
    "files.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "for s in range(len(files)):\n",
    "    position=file_path+files[s]\n",
    "    df=pd.read_csv(position,encoding='gbk')\n",
    "    df.set_index('herb',inplace=True)\n",
    "    herb=list(df.columns)\n",
    "    dg=list(df.apply(lambda x:x.sum(),axis=1))\n",
    "    dict1={}\n",
    "    for i in range(len(herb)):\n",
    "        dict1[herb[i]]=dg[i]\n",
    "    dict2=sorted(dict1.items(),key=lambda x:x[1],reverse=True)\n",
    "    new_herb=[]\n",
    "    for item in dict2:\n",
    "        new_herb.append(item[0])\n",
    "    df=df.loc[new_herb,new_herb]\n",
    "    df.to_csv(position,encoding='gbk')\n",
    "\n",
    "#null model common neighbor data\n",
    "file_path='D:Fig_2/null_model_data/'\n",
    "files=os.listdir(file_path)\n",
    "files.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "file_path1='D:Fig_2/null_model_common_neighbor/'\n",
    "for s in range(len(files)):\n",
    "    position=file_path+files[s]\n",
    "    df=pd.read_csv(position,encoding='gbk')\n",
    "    df.set_index('herb',inplace=True)\n",
    "    herb=list(df.columns)\n",
    "    position1=file_path1+files[s]\n",
    "    df1=pd.read_csv(position1,encoding='gbk')\n",
    "    df1.set_index('herb',inplace=True)\n",
    "    df1=df1.loc[herb,herb]\n",
    "    df1.to_csv(position1,encoding='gbk')\n",
    "\n",
    "#calculate the NODF value of the random network\n",
    "file_path1='D:Fig_2/null_model_data/'\n",
    "file_path2='D:Fig_2/null_model_common_neighbor/'\n",
    "files1=os.listdir(file_path1)\n",
    "files1.sort(key=lambda x:int(x.split('/')[-1].split('_')[0]))\n",
    "times=[]\n",
    "NODF=[]\n",
    "for s in range(len(files1)):\n",
    "    print(files1[s])\n",
    "    time=files1[s].replace('.csv','')\n",
    "    position1=file_path1+files1[s]\n",
    "    position2=file_path2+files1[s]\n",
    "    df1=pd.read_csv(position1,encoding='gbk')\n",
    "    df1.set_index('herb',inplace=True)\n",
    "    degree=list(df1.apply(lambda x:x.sum(),axis=0))\n",
    "    df2=pd.read_csv(position2,encoding='gbk')\n",
    "    df2.set_index('herb',inplace=True)\n",
    "\n",
    "    NR2=[]\n",
    "    for i in range(len(df2)):\n",
    "        NR1=[]\n",
    "        for j in range(len(df2)):\n",
    "            if j > i:\n",
    "                if degree[j] == 0:\n",
    "                    NR1.append(0)\n",
    "                else:\n",
    "                    NR1.append(df2.iloc[i,j]/degree[j])\n",
    "        sum_r=sum(NR1)\n",
    "        NR2.append(sum_r)\n",
    "    NODF.append((sum(NR2)*2)/(len(df2)*(len(df2)-1)))\n",
    "    times.append(time)\n",
    "new_df=pd.DataFrame()\n",
    "new_df['time']=times\n",
    "new_df['NODF']=NODF\n",
    "new_df.to_csv('D:Fig_2/null_model_nestedness.csv',index=False,encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Fig.2B\n",
    "df1=pd.read_csv('D:Fig_2/nestedness/original_nestedness.csv',encoding='gbk')\n",
    "df2=pd.read_csv('D:Fig_2/nestedness/null_model_nestedness.csv',encoding='gbk')\n",
    "\n",
    "time=list(df1['time'])\n",
    "NODF_1=list(df1['NODF'])\n",
    "NODF_2=list(df2['NODF'])\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax1=plt.subplot(1,1,1)\n",
    "ax1.plot(time,NODF_1,c='green',marker='^',label='TCM')\n",
    "ax1.plot(time,NODF_2,c='red',marker='*',label='null model')\n",
    "ax1.set_xlabel('time',fontsize=15)\n",
    "ax1.set_ylabel('NODF',fontsize=15)\n",
    "ax1.set_xticklabels(time, rotation=90,fontsize=15)\n",
    "ax1.set_yticklabels([0.00,0.00,0.05,0.10,0.15,0.20,0.25,0.30,0.35], fontsize=15)\n",
    "ax1.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1))\n",
    "ax1.axvline(0,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(1.2,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(4.81,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(8.6,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(12.68,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(15.44,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(18.11,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.axvline(19,ls=\"--\",linewidth=0.3,c=\"black\")\n",
    "ax1.text(-0.45,0.27,'before the\\nend of Han\\n Dynasty',fontsize=15)\n",
    "ax1.text(2.1,0.26,'Wei,Jin,\\nSouthern and\\nNorthern\\nDynasties'.center(3),fontsize=15)\n",
    "ax1.text(6.1,0.27,'Sui,Tang\\nand Five\\nDynasties'.center(8),fontsize=15)\n",
    "ax1.text(10.1,0.27,'Song,Jin\\nand Yuan\\nDynasties'.center(11),fontsize=15)\n",
    "ax1.text(13.3,0.27,'Ming\\nDynasty'.center(14),fontsize=15)\n",
    "ax1.text(16.2,0.27,'Qing\\nDynasty'.center(16),fontsize=15)\n",
    "ax1.text(18.,0.27,'Modern\\nTimes'.center(-5),fontsize=15)\n",
    "font1 = { 'size': 15 }\n",
    "plt.legend(loc='lower center',bbox_to_anchor=(0.8, 0.03),ncol=2,prop=font1 )\n",
    "plt.savefig('D:Fig_2/compare_nestedness.TIFF',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Fig.3C\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "df=pd.read_csv('D:Fig_2/original_data/1901_2016.csv',encoding='gbk')\n",
    "df.set_index('herb1',inplace=True)\n",
    "df[df>1]=1\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax=plt.subplot(1,1,1)\n",
    "sns.heatmap(df, xticklabels=False, yticklabels=False,cmap='binary')  \n",
    "ls=list(df.apply(lambda x: x.sum(), axis=1))\n",
    "x=[]\n",
    "for i in range(len(df)):\n",
    "    x.append(i+1)\n",
    "ax.plot(x,ls,color='orangered')\n",
    "ax.set_xlabel('components',fontsize=15)\n",
    "ax.set_ylabel('components',fontsize=15)\n",
    "ax.set_title('TCM(1901-2016)',fontsize=15)\n",
    "plt.savefig('D:Fig_2/original_1901_2016.TIFF',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Fig.3D\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "df=pd.read_csv('D:Fig_2/null_model_data/1901_2016.csv',encoding='gbk')\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax=plt.subplot(1,1,1)\n",
    "sns.heatmap(df, xticklabels=False, yticklabels=False,cmap='binary')  \n",
    "ax.set_xlabel('components',fontsize=15)\n",
    "ax.set_ylabel('components',fontsize=15)\n",
    "ax.set_title('null model(1901-2016)',fontsize=15)\n",
    "plt.savefig('D:Fig_2/null_model_1901_2016.TIFF',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
